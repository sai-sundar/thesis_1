% Chapter 1

\chapter{Conclusions and Perspectives} % Main chapter title

\label{Chapter6} % For referencing the chapter elsewhere, use \ref{Chapter1} 

%----------------------------------------------------------------------------------------
The focus in this thesis has been to utilize established neural networks with proposed modifications to suit various aspects of tomographic image reconstruction. A three-stage framework was presented in the form of DUG-RECON, in which each of the stages has a task specific neural network. The first network is a U-Net with a residual connection that denoises the sinogram, the second network, U-Net without the residual connection, maps the denoised sinogram to a reconstruction image estimate and the final stage improves the quality of the image estimate with a residual block. All the neural networks involved are based on \acp{CNN} without any \ac{FC} layers, making it relatively easy for training. The results were quantitatively analyzed and compared with traditional reconstruction approaches and also a deep learning based direct image reconstruction method DeepPET. The second proposed method \ac{LRRCED} demonstrated with DenseNet and U-Net for sparse-view CT reconstruction, uses information from sinogram and low-resolution \ac{FBP} estimates to produce a reconstructed image. This method was also validated on real clinical data for sparse-view CT problem. An ablation study was performed to highlight the impact of different components of the LRRCED. Additionally, we tried to address instability in neural networks with different sinogram sampling as pointed out by \cite{antun2020instabilities}. DenseNet, U-Net and ResNet were the base neural network architectures utilized in this thesis. The proposed changes suggested in both the aforementioned approaches, made them specifically suitable for tomographic image reconstruction. 

One of the key challenges involved with training neural networks is fine-tuning the hyper-parameters. Some of the hyper-parameters like number of filters in the first layer, the factor of multiplicity of filters can be inspired from established benchmarks in tasks like segmentation. Once the hyper-parameters related to the design are fixed, questions related to data and the training duration can be addressed. Though there is a clear interdependence of these hyper-parameters, network design is a more straightforward problem to address thanks to the already existing literature. Typically the strategy used to select the hyper-parameters is to monitor the loss on the validation dataset. Sometimes additional metrics different to that of the loss function are also used to help in fine-tuning the hyper-parameters (\cite{zhang2018sparse}). In image reconstruction as the task is to estimate an image, visual inspection also provides an added advantage to monitor the network training at intermediate steps. 

Data preparation is another important aspect which needs to be addressed before the network can actually be trained. Typically the publicly available human patient data is in the DICOM format which needs to pre-processed and then stored efficiently in formats suitable for the machine learning library. The machine learning library used in this thesis was TensorFlow. Since in image reconstruction the final values in the image pixel are important, normalization of data needs to be carefully managed. It is a common practice to normalize the data prior to training a \ac{CNN} as it helps in faster convergence. However, the scaling required to get back to the original values can lead to loss of information. The range of values in the images are very different for \ac{PET} and \ac{CT}. In \ac{PET} we estimate the tracer activity distribution while in \ac{CT} we estimate the attenuation. The former has large values in the orders of $10^4-10^6$ subject to the dose and the tracer, while the latter has lower values in the order of $10^{-2}$ depending on the energy of the X-rays. For un-normalized data the last layer of the \ac{CNN} needs to have either a linear activation function or a version of ReLU for the estimate predicted by the network to have values in the same range as the image. It is to be noted that convergence could be effected for un-normalized data and the network may need to be trained for a higher number of epochs. For \ac{CT} imaging, a format often used for displaying is the HUT, different HUT windows are used to observe organ specific details. However, a network is typically trained with attenuation images, and a conversion is required to display the images. Hence, the range of values in the images estimated become very important.

Transfer learning in neural network terminology refers to taking a network trained on a large dataset and fine-tuning it's weights to smaller datasets. It is often used in cases where there is dearth of data. It also becomes an important strategy to make the network adapt to changes in the data environment (for example different acquisition geometry). All the weights if the network could be updated by training on the smaller dataset or only the weights of the last few layers. We chose to update the weights of all the layers across the network. The LRRCED was initialized with the weights of the larger semi-simulated dataset, (real patient images-synthesized sinograms) and then trained on the Mayo CT clinical dataset. The reconstructed images reflected the quantitative metrics similar to that of the simulated dataset. With one of the primary challenges of neural network approaches being generalization to new data, transfer learning seems to be a viable option for supervised learning. 

The most commonly used datasets for \ac{PET} and \ac{CT} image reconstruction problems are BrainWeb (\cite{cocosco1997brainweb}) and Mayo Clinic database (\cite{moen2021low}) respectively. However, there is a lack of a bench-marking dataset designed specifically to test deep learning-based approaches. The various data-driven methods proposed across the years use different datasets and data preparation techniques making it difficult to reproduce the results for fair comparison. Even the hyper-parameter fine-tuning gets challenging when the source code and the dataset are not made public. Also for real clinical datasets, it is important to have access to all the geometry/physics information for realistic modeling of the system matrix, essential in the creation of projection/back-projection operators. Standardization of data and comparison criteria is paramount to establish state of the art methods through fair and universally accepted evaluation.

The stability of deep learning-based reconstruction methods has been extensively studied in \cite{antun2020instabilities}. The authors designed a stability test aimed to check the feasibility of these methods for practical usage. They divided potential instabilities into three main categories: (i) small perturbations either in the data or the image may lead to inexplicable artifacts in the reconstructed images; (ii) small structural changes in the image may be missed out in the reconstructed images; (iii) increase in sampling of the data may degrade the reconstruction. The authors observed that direct neural network approaches seemed most unstable when compared to hybrid and post-processing methods. In our experiments with sparse-view CT reconstruction featuring \ac{LRRCED}, we analyzed the effect of change in the sparsity of sinograms on the reconstructed images. We observed that increase in sampling (reduction in sparsity) either improved the image or at-least maintained the same image quality. The LRRCED which is a method that combines both denoising and direct reconstruction approaches, was found to be stable with the increase in measurement data sampling. Additional experiments based on the article are being designed to develop a methodology for ensuring stable deep learning-based image reconstruction methods. 

Medical images of a particular modality share a lot of similarities and redundancies. When a radiologist looks at a \ac{CT} or \ac{PET} image his attention is drawn to a particular area that is relevant for scrutiny. This brings into context the recently developed self attention mechanism that helps neural networks focus on important task-specific information. In natural language processing attention mechanism helps identify the context of a sentence and which words in a sentence are more important for translation etc. \acp{CNN} have recently been combined with the attention mechanism to improve segmentation (\cite{li2020attention,hu2020parallel}). For low-dose \ac{PET} image denoising, \cite{xue20203d} proposed a network that combined attention mechanism with \ac{GAN}. Similarly, \cite{du2019visual} demonstrated the effectiveness of visual attention network for low-dose \ac{CT} denoising. Transformers (\cite{vaswani2017attention}) have revolutionized the field of natural language processing and have recently been applied to computer vision (\cite{khan2021transformers}). The transformer module which uses a global attention scheme, is typically embedded in the encoder part of a \ac{CED}. Works like \cite{chen2021transunet} use transformer in the encoder of the U-Net, to explicitly model long range dependency. In \cite{luo20213d}, the authors combined the concepts of transformers and \acs{GAN} to propose a 3-D network for \ac{PET} image denoising. We are currently working on incorporating the transformer modules in the networks proposed as a part of this thesis, for direct image reconstruction task for both \ac{PET} and \ac{CT} modalities.

Recently many unsupervised methods have been proposed for image denoising. Unsupervised methods, unlike the approaches discussed so far in this thesis (apart from deep image prior), do not need to be trained on labeled data for a dedicated task. As denoising is an integral part of image reconstruction, these new methods have immense potential to improve the reconstructed images in low dose imaging. \cite{yuan2020half2half} proposed an approach called Half2Half that does denoising for \ac{CT} images without the use of high quality reference data. The authors proposed a novel method to generate training input and training label from the same \ac{CT} scan. The denoising network is then trained on these data alone without the requirement of additional high dose \ac{CT} data. For \ac{PET} denoising, \cite{chan2019noise} trained a neural network to map from one noise realization to an ensemble of noise realizations. Currently most of the unsupervised denosing approaches either 


%Recorrupted-to-Recorrupted is an approach for real-world imaging proposed by \cite{pang2021recorrupted}, that is claimed to have the state of the art performance among unsupervised denoising methods and is comparable to many supervised methods.  