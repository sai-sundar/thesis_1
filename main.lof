\boolfalse {citerequest}\boolfalse {citetracker}\boolfalse {pagetracker}\boolfalse {backtracker}\relax 
\babel@toc {english}{}
\addvspace {10\p@ }
\contentsline {figure}{\numberline {1.1}{\ignorespaces Depiction of a circular \ac {PET} detector with detectors $d_p$ and $d_q$ connected with a \ac {LOR} indicated in gray.\relax }}{2}{figure.caption.21}
\contentsline {figure}{\numberline {1.2}{\ignorespaces Depiction of Compton scatter\relax }}{4}{figure.caption.26}
\contentsline {figure}{\numberline {1.3}{\ignorespaces Depiction of Photo-electric effect\relax }}{4}{figure.caption.27}
\contentsline {figure}{\numberline {1.4}{\ignorespaces Fan-beam geometry: the source and the detector rotate around the object\relax }}{5}{figure.caption.31}
\contentsline {figure}{\numberline {1.5}{\ignorespaces Cone-beam geometry: the source rotates around the patient while the bed is translated creating a helical scan.\relax }}{6}{figure.caption.32}
\addvspace {10\p@ }
\contentsline {figure}{\numberline {2.1}{\ignorespaces Depiction of a neural network with an input layer, three hidden layers and an output layer\relax }}{16}{figure.caption.70}
\contentsline {figure}{\numberline {2.2}{\ignorespaces Computational graph with one hidden layer. The nodes in the first layer store the input $x$, weight $w$ and the bias $b$. The second layer contains the hidden layer with 2 units each with the corresponding operation written below. The final layer is the output layer denoted by $\mathaccentV {hat}45E{y}=\sigma (wx+b)$, where $\sigma $ is the sigmoid function defined earlier.\relax }}{19}{figure.caption.80}
\contentsline {figure}{\numberline {2.3}{\ignorespaces Convolution of an input image of dimensions 5$\times $5 with a filter of dimensions 3$\times $3.(\cite {dumoulin2016guide})\relax }}{24}{figure.caption.102}
\contentsline {figure}{\numberline {2.4}{\ignorespaces The \ac {ReLU} function\relax }}{24}{figure.caption.104}
\contentsline {figure}{\numberline {2.5}{\ignorespaces Max pooling with 2$\times $2 filter and stride 1\relax }}{25}{figure.caption.106}
\contentsline {figure}{\numberline {2.6}{\ignorespaces Architecture of a typical \ac {CNN}. This representation was first proposed by \cite {lecun1995convolutional}.\relax }}{26}{figure.caption.107}
\contentsline {figure}{\numberline {2.7}{\ignorespaces Transposed convolution over a $2\times 2$ input to get a $4\times 4$ output. (\cite {dumoulin2016guide})\relax }}{26}{figure.caption.109}
\contentsline {figure}{\numberline {2.8}{\ignorespaces \ac {CNN} for image to image translation tasks. This example has an identical structure in convolution path and the transposed convolution path.\relax }}{27}{figure.caption.110}
\addvspace {10\p@ }
\contentsline {figure}{\numberline {3.1}{\ignorespaces Deep Learning in Medical Image Reconstruction\relax }}{30}{figure.caption.112}
\addvspace {10\p@ }
\contentsline {figure}{\numberline {4.1}{\ignorespaces Proposed Deep Learning pipeline for Direct Image Reconstruction\relax }}{44}{figure.caption.146}
\contentsline {figure}{\numberline {4.2}{\ignorespaces Representation of the denoising network. The inputs to the network were \ac {2D} grayscale slices with resolution $128\times {}128$ and the outputs were denoised sinograms.\relax }}{46}{figure.caption.150}
\contentsline {figure}{\numberline {4.3}{\ignorespaces Representation of the \ac {DUGAN}, the image reconstruction block. This network was trained on denoised sinograms which were the outputs of the previous segment.\relax }}{47}{figure.caption.155}
\contentsline {figure}{\numberline {4.4}{\ignorespaces Representation of the super resolution block. It consists of 8 residual blocks with Convolution, Batch normalization and PReLu.\relax }}{48}{figure.caption.161}
\contentsline {figure}{\numberline {4.5}{\ignorespaces Data preparation\relax }}{49}{figure.caption.164}
\contentsline {figure}{\numberline {4.6}{\ignorespaces Example PET sinogram-image pairs from the dataset\relax }}{50}{figure.caption.165}
\contentsline {figure}{\numberline {4.7}{\ignorespaces Example CT sinogram-image pairs from the dataset \relax }}{51}{figure.caption.167}
\contentsline {figure}{\numberline {4.8}{\ignorespaces Representation of DeepPET. The number of filters in each convolutional layer is labeled on top of each block.\relax }}{52}{figure.caption.174}
\contentsline {figure}{\numberline {4.9}{\ignorespaces Image predictions by \ac {DUGAN}+SR, DeepPET and \ac {GT} for four \ac {PET} Images from different parts of the patient volume\relax }}{54}{figure.caption.178}
\contentsline {figure}{\numberline {4.10}{\ignorespaces \ac {SNR} and \ac {CNR} comparison amongst DUG+SR and OSEM for \ac {PET} image along 4 regions of interest\relax }}{54}{figure.caption.180}
\contentsline {figure}{\numberline {4.11}{\ignorespaces Image predictions by \ac {DUGAN}+ \ac {SR}, DeepPET and \ac {GT} are displayed for 3 \ac {CT} Images along different parts of the patient volume.\relax }}{55}{figure.caption.181}
\contentsline {figure}{\numberline {4.12}{\ignorespaces \ac {SNR} and \ac {CNR} comparison amongst DUG+SR and OSEM for \ac {CT} image along 4 regions of interest\relax }}{55}{figure.caption.182}
\contentsline {figure}{\numberline {4.13}{\ignorespaces Intensity Profile across the image (highlighted by a yellow line) for a \ac {PET} image prediction by \ac {DUGAN}, \ac {DUGAN}+SR and DeepPET compared with the \ac {GT}\relax }}{57}{figure.caption.183}
\contentsline {figure}{\numberline {4.14}{\ignorespaces Intensity Profile for two \ac {CT} images (highlighted by a yellow line) predicted by \ac {DUGAN} and \ac {SR} compared with the \ac {GT}\relax }}{58}{figure.caption.184}
\addvspace {10\p@ }
\contentsline {figure}{\numberline {5.1}{\ignorespaces General representation of an encoder-decoder architecture with fully convolutional layers and the proposed \ac {FBP} concatenations ($\bm {x}_1$ and $\bm {x}_2$) at two different resolutions $h_1 \times w_1$ and $h_2 \times w_2$\relax }}{65}{figure.caption.191}
\contentsline {figure}{\numberline {5.2}{\ignorespaces Different components of \ac {LRRCED}(D): \subref {fig:db} Representation of a dense block with three layers. \subref {fig:dn1} \ac {LRRCED}(D): Fully convolutional dense network with $\bm {x}_1$ at $64\times 64$ and $\bm {x}_2$ at $128\times 128$. \subref {fig:dn2} Complete architecture summary\relax }}{68}{figure.caption.199}
\contentsline {figure}{\numberline {5.3}{\ignorespaces Different components of \ac {LRRCED}(U): \subref {fig:un} \ac {LRRCED}(U): U-Net with $\bm {x}_1$ at $64\times 64$ and $\bm {x}_2$ at $128\times 128$. \subref {fig:ud} Complete architecture summary.\relax }}{69}{figure.caption.200}
\contentsline {figure}{\numberline {5.4}{\ignorespaces Samples from the dataset: Sinograms with different sparse-view configurations along with their corresponding \ac {FBP} estimate.\relax }}{72}{figure.caption.207}
\contentsline {figure}{\numberline {5.5}{\ignorespaces Images reconstructed with LRR-CED(D) approach with different sparse-view configurations, i.e., projections with $N_\mathrm {a}=120,90,60,40$ and $20$. For better visual inspection images in first row are displayed in $-40 \pm 600$ HUT window, the second row in $-340 \pm 400$ HUT and the third in $-150 \pm 400$ HUT.\relax }}{75}{figure.caption.216}
\contentsline {figure}{\numberline {5.6}{\ignorespaces Images reconstructed with LRR-CED(U) approach with different Sparse-View configurations, i.e., projections with $N_\mathrm {a}=120,90,60,40$ and $20$. Images in first row are displayed in $-40 \pm 600$ HUT window, the second row in $-340 \pm 400$ HUT and the third in $-150 \pm 400$ HUT.\relax }}{75}{figure.caption.217}
\contentsline {figure}{\numberline {5.7}{\ignorespaces Comparative analysis for 60 views: From the top left corner, we have \ac {GT} image, reconstructions with \ac {LRRCED}(D) . In the second row reconstructed images with \ac {LRRCED}(U) and FBP-ConvNet. Finally images reconstructed with PWLS-TV and \ac {FBP}.\relax }}{76}{figure.caption.220}
\contentsline {figure}{\numberline {5.8}{\ignorespaces Comparative analysis for 90 views: From the top left corner, we have \ac {GT} image, reconstructions with \ac {LRRCED}(D) . In the second row reconstructed images with \ac {LRRCED}(U) and FBP-ConvNet. Finally images reconstructed with PWLS-TV and \ac {FBP}.\relax }}{77}{figure.caption.221}
\contentsline {figure}{\numberline {5.9}{\ignorespaces Intensity plot profile for the region marked in red from Fig.~\ref {fig:res_60} comparing \ac {LRRCED}(D) and FBP-ConvNet to the \ac {GT} in \subref {fig:ip_60_d} and \ac {LRRCED}(U) and FBP-ConvNet in \subref {fig:ip_60_u}\relax }}{78}{figure.caption.222}
\contentsline {figure}{\numberline {5.10}{\ignorespaces Intensity plot profile for the region marked in red from Fig.~\ref {fig:res_90} comparing \ac {LRRCED}(D) and FBP-ConvNet to the \ac {GT} in \subref {fig:ip_90_d} and \ac {LRRCED}(U) and FBP-ConvNet in \subref {fig:ip_90_u}\relax }}{78}{figure.caption.223}
\contentsline {figure}{\numberline {5.11}{\ignorespaces Real data study: Images reconstructed with the proposed approaches across 4 different slices displayed in the window $40 \pm 200 $ HUT. \relax }}{79}{figure.caption.225}
\contentsline {figure}{\numberline {5.12}{\ignorespaces Stability study: Each row corresponds to the network trained on specific value of $N_\mathrm {a}$, and tested with all the possible values of $N_\mathrm {a}$.\relax }}{81}{figure.caption.228}
\contentsline {figure}{\numberline {5.13}{\ignorespaces Comparison of single concatenations for the particular case of 90 views evaluated with \ac {SSIM} on 5 different patients from the dataset. The best metrics are found with concatenation at $128\times 128$.\relax }}{84}{figure.caption.235}
\contentsline {figure}{\numberline {5.14}{\ignorespaces Comparison of double concatenations for the particular case of 90 views evaluated with \ac {SSIM} on 5 different patients from the dataset. The best metrics are found with concatenations at $64\times 64$ and $128\times 128$ resolutions.\relax }}{84}{figure.caption.236}
\contentsline {figure}{\numberline {5.15}{\ignorespaces Comparison of Average \ac {SSIM} for 5 different Patient data for 90 views with varying number of training samples. The configuration of the network is the one with best performance from the analysis in Figure~\ref {fig:c1}. (concatenations at $64\times 64$ and $128\times 128$). \relax }}{85}{figure.caption.237}
\contentsline {figure}{\numberline {5.16}{\ignorespaces Schematic representation of configurations used in the ablation study: (i) true sinogram and the reconstructed image only (no low-resolution concatenations); (ii) randomly distributed Gaussian noise sinogram, low-resolution concatenations and the reconstructed images; (iii) true sinogram, low-resolution concatenations and the reconstructed images.\relax }}{85}{figure.caption.238}
\contentsline {figure}{\numberline {5.17}{\ignorespaces Ablation study: Predictions from different configurations of the network.\relax }}{86}{figure.caption.239}
\addvspace {10\p@ }
\addvspace {10\p@ }
