\boolfalse {citerequest}\boolfalse {citetracker}\boolfalse {pagetracker}\boolfalse {backtracker}\relax 
\babel@toc {english}{}
\addvspace {10\p@ }
\contentsline {figure}{\numberline {1.1}{\ignorespaces Depiction of a circular \ac {PET} detector with detectors $d_p$ and $d_q$ connected with a \ac {LOR} indicated in gray.\relax }}{2}{figure.caption.19}
\contentsline {figure}{\numberline {1.2}{\ignorespaces Depiction of Compton scatter\relax }}{4}{figure.caption.24}
\contentsline {figure}{\numberline {1.3}{\ignorespaces Depiction of Photo-electric effect\relax }}{4}{figure.caption.25}
\contentsline {figure}{\numberline {1.4}{\ignorespaces Fan-beam geometry: the source and the detector rotate around the object\relax }}{5}{figure.caption.28}
\contentsline {figure}{\numberline {1.5}{\ignorespaces Cone-beam geometry: the source rotates around the patient while the bed is translated creating a helical scan.\relax }}{6}{figure.caption.29}
\addvspace {10\p@ }
\contentsline {figure}{\numberline {2.1}{\ignorespaces Depiction of a neural network with an input layer, three hidden layers and an output layer\relax }}{14}{figure.caption.64}
\contentsline {figure}{\numberline {2.2}{\ignorespaces Computational graph with one hidden layer. The nodes in the first layer store the input $x$, weight $w$ and the bias $b$. The second layer contains the hidden layer with 2 units each with the corresponding operation written below. The final layer is the output layer denoted by $\mathaccentV {hat}45E{y}=\sigma (wx+b)$, where $\sigma $ is the sigmoid function defined earlier.\relax }}{17}{figure.caption.74}
\contentsline {figure}{\numberline {2.3}{\ignorespaces Convolution of an input image of dimensions 5$\times $5 with a filter of dimensions 3$\times $3.(\cite {dumoulin2016guide})\relax }}{21}{figure.caption.95}
\contentsline {figure}{\numberline {2.4}{\ignorespaces The \ac {ReLU} function\relax }}{22}{figure.caption.97}
\contentsline {figure}{\numberline {2.5}{\ignorespaces Max pooling with 2$\times $2 filter and stride 1\relax }}{22}{figure.caption.99}
\contentsline {figure}{\numberline {2.6}{\ignorespaces Architecture of a typical \ac {CNN}. This representation was first proposed by \cite {lecun1995convolutional}.\relax }}{23}{figure.caption.100}
\contentsline {figure}{\numberline {2.7}{\ignorespaces Transposed convolution over a $2\times 2$ input to get a $4\times 4$ output. (\cite {dumoulin2016guide})\relax }}{24}{figure.caption.102}
\contentsline {figure}{\numberline {2.8}{\ignorespaces \ac {CNN} for image to image translation tasks. This example has an identical structure in convolution path and the transposed convolution path.\relax }}{24}{figure.caption.103}
\addvspace {10\p@ }
\contentsline {figure}{\numberline {3.1}{\ignorespaces Deep Learning in Medical Image Reconstruction\relax }}{28}{figure.caption.105}
\contentsline {figure}{\numberline {3.2}{\ignorespaces Direct image reconstruction with deep learning\relax }}{30}{figure.caption.110}
\addvspace {10\p@ }
\contentsline {figure}{\numberline {4.1}{\ignorespaces Proposed Deep Learning pipeline for Direct Image Reconstruction\relax }}{34}{figure.caption.114}
\contentsline {figure}{\numberline {4.2}{\ignorespaces Representation of the denoising network. The inputs to the network were \ac {2D} grayscale slices with resolution $128\times {}128$ and the outputs were denoised sinograms.\relax }}{36}{figure.caption.118}
\contentsline {figure}{\numberline {4.3}{\ignorespaces Representation of the \ac {DUGAN}, the image reconstruction block. This network was trained on denoised sinograms which were the outputs of the previous segment.\relax }}{37}{figure.caption.123}
\contentsline {figure}{\numberline {4.4}{\ignorespaces Representation of the super resolution block. It consists of 8 residual blocks with Convolution, Batch normalization and PReLu.\relax }}{38}{figure.caption.129}
\contentsline {figure}{\numberline {4.5}{\ignorespaces Data preparation\relax }}{39}{figure.caption.132}
\contentsline {figure}{\numberline {4.6}{\ignorespaces Example PET sinogram-image pairs from the dataset\relax }}{40}{figure.caption.133}
\contentsline {figure}{\numberline {4.7}{\ignorespaces Example CT sinogram-image pairs from the dataset \relax }}{41}{figure.caption.135}
\contentsline {figure}{\numberline {4.8}{\ignorespaces Representation of DeepPET. The number of filters in each convolutional layer is labeled on top of each block.\relax }}{42}{figure.caption.142}
\contentsline {figure}{\numberline {4.9}{\ignorespaces Image predictions by \ac {DUGAN}+SR, DeepPET and \ac {GT} for four \ac {PET} Images from different parts of the patient volume\relax }}{44}{figure.caption.146}
\contentsline {figure}{\numberline {4.10}{\ignorespaces \ac {SNR} and \ac {CNR} comparison amongst DUG+SR and OSEM for \ac {PET} image along 4 regions of interest\relax }}{44}{figure.caption.148}
\contentsline {figure}{\numberline {4.11}{\ignorespaces Image predictions by \ac {DUGAN}+ \ac {SR}, DeepPET and \ac {GT} are displayed for 3 \ac {CT} Images along different parts of the patient volume.\relax }}{45}{figure.caption.149}
\contentsline {figure}{\numberline {4.12}{\ignorespaces \ac {SNR} and \ac {CNR} comparison amongst DUG+SR and OSEM for \ac {CT} image along 4 regions of interest\relax }}{45}{figure.caption.150}
\contentsline {figure}{\numberline {4.13}{\ignorespaces Intensity Profile across the image (highlighted by a yellow line) for a \ac {PET} image prediction by \ac {DUGAN}, \ac {DUGAN}+SR and DeepPET compared with the \ac {GT}\relax }}{47}{figure.caption.151}
\contentsline {figure}{\numberline {4.14}{\ignorespaces Intensity Profile for two \ac {CT} images (highlighted by a yellow line) predicted by \ac {DUGAN} and \ac {SR} compared with the \ac {GT}\relax }}{48}{figure.caption.152}
\addvspace {10\p@ }
\contentsline {figure}{\numberline {5.1}{\ignorespaces General representation of an encoder-decoder architecture with fully convolutional layers and the proposed \ac {FBP} concatenations ($\bm {x}_1$ and $\bm {x}_2$) at two different resolutions $h_1 \times w_1$ and $h_2 \times w_2$\relax }}{55}{figure.caption.159}
\contentsline {figure}{\numberline {5.2}{\ignorespaces Representation of a Dense Block with three layers.\relax }}{58}{figure.caption.167}
\contentsline {figure}{\numberline {5.3}{\ignorespaces \ac {LRRCED}(D): Fully convolutional dense network with $\bm {x}_1$ at $64\times 64$ and $\bm {x}_2$ at $128\times 128$.\relax }}{59}{figure.caption.168}
\contentsline {figure}{\numberline {5.4}{\ignorespaces \ac {LRRCED}(U): U-Net with $\bm {x}_1$ at $128\times 128$ and $\bm {x}_2$ at $256\times 256$.\relax }}{60}{figure.caption.170}
\contentsline {figure}{\numberline {5.5}{\ignorespaces Samples from the dataset: Sinograms with different sparse-view configurations along with their corresponding \ac {FBP} estimate.\relax }}{62}{figure.caption.177}
\contentsline {figure}{\numberline {5.6}{\ignorespaces Images reconstructed with LRR-CED(D) approach with different sparse-view configurations, i.e., projections with $N_\mathrm {a}=60,90$ and $120$.\relax }}{64}{figure.caption.186}
\contentsline {figure}{\numberline {5.7}{\ignorespaces Images reconstructed with LRR-CED(U) approach with different Sparse-View configurations, i.e., projections with $N_\mathrm {a}=60,90$ and $120$.\relax }}{65}{figure.caption.187}
\contentsline {figure}{\numberline {5.8}{\ignorespaces Comparative analysis for 60 views: From the top left, we have \ac {GT} image, reconstructions with \ac {LRRCED}(D) and \ac {LRRCED}(U). In the second row reconstructed images with FBP-ConvNet, PWLS-TV and \ac {FBP}. \relax }}{66}{figure.caption.190}
\contentsline {figure}{\numberline {5.9}{\ignorespaces Comparative analysis for 90 views: From the top we have \ac {GT} image, reconstructions with \ac {LRRCED}(D) and \ac {LRRCED}(U). In the second row reconstructed images with FBP-ConvNet, PWLS-TV and \ac {FBP}.\relax }}{67}{figure.caption.191}
\contentsline {figure}{\numberline {5.10}{\ignorespaces Intensity plot profile for the region marked in red from Figure~\ref {fig:res_60} for PWLS-TV, \ac {GT}, \ac {LRRCED}(D), \ac {LRRCED}(U) and FBP-ConvNet.\relax }}{68}{figure.caption.192}
\contentsline {figure}{\numberline {5.11}{\ignorespaces Intensity plot profile for the region marked in red from Figure~\ref {fig:res_90} for PWLS-TV, \ac {GT}, \ac {LRRCED}(D), \ac {LRRCED}(U) and FBP-ConvNet.\relax }}{68}{figure.caption.193}
\contentsline {figure}{\numberline {5.12}{\ignorespaces Comparison of single concatenations for the particular case of 90 views evaluated with \ac {SSIM} on 5 different patients from the dataset. The best metrics are found with concatenation at $128\times 128$.\relax }}{70}{figure.caption.199}
\contentsline {figure}{\numberline {5.13}{\ignorespaces Comparison of double concatenations for the particular case of 90 views evaluated with \ac {SSIM} on 5 different patients from the dataset. The best metrics are found with concatenations at $64\times 64$ and $128\times 128$ resolutions.\relax }}{71}{figure.caption.200}
\contentsline {figure}{\numberline {5.14}{\ignorespaces Comparison of Average \ac {SSIM} for 5 different Patient data for 90 views with varying number of training samples. The configuration of the network is the one with best performance from the analysis in Figure~\ref {fig:c1}. (concatenations at $64\times 64$ and $128\times 128$). \relax }}{71}{figure.caption.201}
\addvspace {10\p@ }
